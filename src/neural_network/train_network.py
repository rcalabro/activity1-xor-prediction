import numpy as np

"""
Este m√≥dulo foi gerado inicialmente pelo ChatGPT e posteriormente modificado manualmente 
para incluir um algoritmo de treinamento experimental.

Implementa um treinamento **aleat√≥rio** para testes, sem utilizar Gradiente Descendente.
Os pesos e bias da rede s√£o atualizados aleatoriamente para minimizar uma fun√ß√£o de custo.

Autor: Renato Calabro
"""

def train_network(nn, X, y, epochs=100, learning_rate=0.1, target_error=0.01):
    """
    Treina uma rede neural `nn` ajustando pesos e bias de forma aleat√≥ria.

    Par√¢metros:
    - nn: Inst√¢ncia de NeuralNetwork j√° inicializada.
    - X: Dados de entrada (shape: [amostras, neur√¥nios de entrada]).
    - y: Dados de sa√≠da esperados (shape: [amostras, neur√¥nios de sa√≠da]).
    - epochs: N√∫mero m√°ximo de √©pocas de treinamento (padr√£o: 100).
    - learning_rate: Taxa de aprendizado para ajustar os pesos aleatoriamente (padr√£o: 0.1).
    - target_error: Valor limite para o erro, onde o treinamento ser√° interrompido se atingido (padr√£o: 0.01).

    Retorna:
    - Hist√≥rico de erro em cada √©poca.
    - N√∫mero de √©pocas executadas.
    """

    history = []  # Para armazenar a fun√ß√£o de custo em cada √©poca

    for epoch in range(epochs):
        # üîπ Forward pass: Faz a predi√ß√£o da rede
        y_pred = nn.predict(X)

        # üîπ Calcula a fun√ß√£o de custo (Erro Quadr√°tico M√©dio - MSE)
        loss = np.mean((y_pred - y) ** 2)
        history.append(loss)

        # üîπ Verifica se atingiu o erro alvo
        if loss <= target_error:
            print(f"\n‚úÖ Treinamento encerrado na √©poca {epoch+1}: Erro atingiu {loss:.6f} (meta: {target_error})")
            break

        # üîπ Atualiza pesos e bias aleatoriamente (apenas para testes)
        for i in range(len(nn.weights)):
            nn.weights[i] += np.random.randn(*nn.weights[i].shape) * learning_rate
            nn.biases[i] += np.random.randn(*nn.biases[i].shape) * learning_rate

        # üîπ Exibe o progresso do treinamento a cada 10% das √©pocas ou na √∫ltima
        if epoch % (epochs // 10) == 0 or epoch == epochs - 1:
            print(f"√âpoca {epoch+1}/{epochs} - Erro: {loss:.6f}")

    return history, epoch + 1  # Retorna o hist√≥rico e o n√∫mero real de √©pocas executadas
