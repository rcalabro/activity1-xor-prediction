import time
import numpy as np
from .activation_functions import ACTIVATIONS, ACTIVATION_DERIVATIVES

"""
ImplementaÃ§Ã£o baseada no livro "Make Your Own Neural Network" de Tariq Rashid, 
com adaptaÃ§Ãµes especÃ­ficas para atender Ã s necessidades do projeto.

- Ajustes na inicializaÃ§Ã£o dos pesos e bias.
- Uso de funÃ§Ãµes de ativaÃ§Ã£o configurÃ¡veis.
- Estrutura modular para facilitar expansÃ£o e manutenÃ§Ã£o.
- Melhorias na legibilidade e organizaÃ§Ã£o do cÃ³digo.
- ValidaÃ§Ã£o dos pesos e bias fornecidos.

AlteraÃ§Ãµes foram feitas manualmente conforme necessidade, utilizando pontualmente 
o ChatGPT para otimizaÃ§Ã£o e refinamento de trechos especÃ­ficos.

Autor: Renato Calabro
"""


class NeuralNetwork:
    def __init__(self,
                 input_layer,
                 hidden_layers,
                 output_layer,
                 activation="sigmoid",
                 output_classification=None,
                 weights=None,
                 biases=None,
                 verbose=False):
        """
        Construtor da classe NeuralNetwork.

        ParÃ¢metros:
        - input_layer: NÃºmero de neurÃ´nios na camada de entrada.
        - hidden_layers: Lista contendo o nÃºmero de neurÃ´nios em cada camada oculta. Ex: [6, 6].
        - output_layer: NÃºmero de neurÃ´nios na camada de saÃ­da.
        - activation: Tipo de funÃ§Ã£o de ativaÃ§Ã£o.
        - weights: Lista opcional de matrizes numpy para os pesos (se None, inicializa aleatÃ³rio).
        - biases: Lista opcional de vetores numpy para os biases (se None, inicializa aleatÃ³rio).
        """

        if verbose:
            print("ðŸ”¹ Inicializando Rde Neural")
            print(f"    Camada de entrada: {input_layer} neurÃ´nios")
            print(f"    Camadas ocultas: {hidden_layers}")
            print(f"    Camada de saÃ­da: {output_layer} neurÃ´nios")
            print(f"    FunÃ§Ã£o de ativaÃ§Ã£o: {activation}")
            print(f"    Pesos iniciais: {'CHECKPOINT' if not weights is None else 'RANDOM'}")
            print(f"    Bias iniciais: {'CHECKPOINT' if not biases is None else 'RANDOM'}\n")
        else:
            print(f"ðŸ”¹ NeuralNetwork: [{input_layer}, {hidden_layers}, {output_layer}] | activation: {activation}\n")

        self.input_layer = input_layer
        self.hidden_layers = hidden_layers
        self.output_layer = output_layer
        self.output_classification = output_classification
        self.verbose = verbose

        # Verifica se a funÃ§Ã£o de ativaÃ§Ã£o requisitada estÃ¡ no dicionÃ¡rio.
        if activation not in ACTIVATIONS:
            raise ValueError(f"FunÃ§Ã£o de ativaÃ§Ã£o '{activation}' nÃ£o suportada. "
                             f"Escolha entre: {list(ACTIVATIONS.keys())}")
        self.activation_func = ACTIVATIONS[activation]
        if activation not in ACTIVATION_DERIVATIVES:
            raise ValueError(f"FunÃ§Ã£o de ativaÃ§Ã£o '{activation}' nÃ£o suportada nÃ£o ter derivada implementada")

        # para treinamento
        self.activation_derivative = ACTIVATION_DERIVATIVES[activation]

        # Lista de pesos e biases
        self.weights = []
        self.biases = []

        # Definir tamanho das camadas
        layer_sizes = [self.input_layer] + self.hidden_layers + [self.output_layer]

        # Validar pesos e bias fornecidos
        if weights is not None and biases is not None:
            if len(weights) != len(layer_sizes) - 1:
                raise ValueError(f"Esperado {len(layer_sizes) - 1} matrizes de pesos, "
                                 f"mas foram recebidas {len(weights)}.")

            if len(biases) != len(layer_sizes) - 1:
                raise ValueError(f"Esperado {len(layer_sizes) - 1} vetores de bias, "
                                 f"mas foram recebidos {len(biases)}.")

        # Inicializar pesos e bias (predefinidos ou aleatÃ³rios)
        for i in range(len(layer_sizes) - 1):
            if weights is not None and biases is not None: # Se foram fornecidos, verifica o formato e usa os valores passados
                if weights[i].shape != (layer_sizes[i], layer_sizes[i+1]):
                    raise ValueError(f"Formato invÃ¡lido para pesos na camada {i+1}: "
                                     f"Esperado ({layer_sizes[i]}, {layer_sizes[i+1]}), "
                                     f"recebido {weights[i].shape}.")

                if biases[i].shape != (1, layer_sizes[i+1]):
                    raise ValueError(f"Formato invÃ¡lido para bias na camada {i+1}: "
                                     f"Esperado (1, {layer_sizes[i+1]}), "
                                     f"recebido {biases[i].shape}.")

                w = weights[i]
                b = biases[i]
            else:  # Se nÃ£o, inicializa aleatoriamente
                w = np.random.randn(layer_sizes[i], layer_sizes[i+1])
                b = np.random.randn(1, layer_sizes[i+1])

            self.weights.append(w)
            self.biases.append(b)

            if verbose:
                print(f"--- Camada {i+1} --> neurons: {layer_sizes[i]} -> {layer_sizes[i+1]}")

        if verbose:
            print("\n>>> Rede Neural Inicializada\n")

    @staticmethod
    def load_checkpoint(path, output_classification=None, verbose=False):
        """
        Carrega uma rede neural salva em checkpoint (.npz) e retorna a instÃ¢ncia pronta.

        ParÃ¢metros:
        - path: caminho para o arquivo .npz gerado com save_checkpoint
        - verbose: se deve imprimir os logs de inicializaÃ§Ã£o
        - output_classification: funÃ§Ã£o opcional de classificaÃ§Ã£o final (ex: lambda x: x > 0.5)

        Retorna:
        - InstÃ¢ncia de NeuralNetwork pronta para uso
        """
        data = np.load(path, allow_pickle=True)

        input_layer = int(data["input_layer"])
        hidden_layers = data["hidden_layers"].tolist()
        output_layer = int(data["output_layer"])
        activation = str(data["activation_func"])
        weights = data["weights"]
        biases = data["biases"]

        return NeuralNetwork(
            input_layer=input_layer,
            hidden_layers=hidden_layers,
            output_layer=output_layer,
            activation=activation,
            weights=weights,
            biases=biases,
            verbose=verbose,
            output_classification=output_classification
        )

    def predict(self, a):
        """
        Executa o forward pass pela rede e retorna a saÃ­da final.
        """

        start = time.perf_counter()
        X = np.array(a)
        for i, (w, b) in enumerate(zip(self.weights, self.biases), start=1):
            z = np.dot(X, w) + b  # MultiplicaÃ§Ã£o matricial + bias
            X = self.activation_func(z)  # Aplica a funÃ§Ã£o de ativaÃ§Ã£o selecionada

        end = time.perf_counter()


        if self.verbose:
            print(f"ðŸ”¹ Forward pass {a} - â±ï¸: {(end - start)*1000:.6f}ms")
            print(f"    --> prediction: - {X.flatten()}")
        if self.output_classification is not None:
            classified = self.output_classification(X)
            if self.verbose:
                print(f"    --> classified: - {classified}")
            return self.output_classification(X)
        return X
