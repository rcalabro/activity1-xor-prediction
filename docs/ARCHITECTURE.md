# üß± Arquitetura da Solu√ß√£o

Este documento descreve a arquitetura geral da solu√ß√£o para a classifica√ß√£o da porta l√≥gica XOR utilizando uma rede neural feedforward, implementada do zero.


## üìä Diagrama de Componentes (Mermaid)

```mermaid
graph TD
    A[main.py] --> B[create_xor_nn]
    A --> C[train_xor]
    A --> D[Trainer]

    B --> E[NeuralNetwork]
    C --> D

    D --> E
    D --> F[Execution Strategy]
    D --> G[Training Strategy]

    subgraph src/neural_network
        E[NeuralNetwork]
        H[activation_functions.py]
    end
     I[analysis/plot_network.py]
     K[analysis/confusion_matrix.py]
     L[analysis/metrics.py]

    subgraph trainer
        F[execution/basic_loop.py]
        G[training/vanilla_backpropagation.py]
        J[loss_functions.py]
    end

    E --> H
    E --> I
    G --> J
    A --> K
    K --> L
```


## üß† Fluxo de Execu√ß√£o

1. `main.py` inicia o processo e decide se ir√° **carregar pesos** existentes ou **treinar uma nova rede**.
2. A rede √© criada via `create_xor_nn`, com a topologia 2-2-1 e ativa√ß√£o sigmoid.
3. Se for necess√°rio treinar:
   - `train_xor` instancia o `Trainer`
   - O `Trainer` conecta uma **estrat√©gia de execu√ß√£o** com uma **estrat√©gia de treinamento**
   - Executa o treinamento com **backpropagation**, utilizando a fun√ß√£o de custo **binary cross-entropy**
4. Os pesos e bias aprendidos s√£o salvos como checkpoint (`.npz`)
5. O script testa os resultados e pode, opcionalmente, **plotar graficamente** a rede com pesos, ativa√ß√µes e conex√µes.


## üóÇÔ∏è Modularidade

- Estrat√©gias de **execu√ß√£o** e **treinamento** s√£o plug√°veis
- Fun√ß√µes de ativa√ß√£o e custo s√£o definidas separadamente
- Visualiza√ß√£o da rede neural √© opcional, por√©m did√°tica

## üß± Arquitetura Resumida

O projeto √© organizado de forma modular para separar responsabilidades:

- üß† **NeuralNetwork**: Lida com estrutura da rede, ativa√ß√£o e forward pass
- üèãÔ∏è **Trainer**: Controla o processo de treinamento e execu√ß√£o
- ‚öôÔ∏è **Strategies**: Estrat√©gias plug√°veis de execu√ß√£o e de atualiza√ß√£o de pesos
- üìä Analysis: Visualiza√ß√£o gr√°fica da rede neural (plot_network) e m√©tricas de avalia√ß√£o (metrics), incluindo acur√°cia, precis√£o, recall e F1-score, com suporte a an√°lise por classe e m√©dias ponderadas.
- üìÅ **Docs**: Toda documenta√ß√£o da atividade e explica√ß√µes t√©cnicas
- üíæ **Checkpoints**: Pesos salvos da rede para evitar reprocessamento
- üöÄ **main.py**: Ponto de entrada da aplica√ß√£o (treina ou testa a rede)

---

> ‚ÑπÔ∏è A arquitetura representada no diagrama acima segue o modelo de um **Perceptron MultiCamadas (MLP)**, com conex√µes totalmente ligadas (fully connected) entre camadas e ativa√ß√£o n√£o linear. Esse modelo √© suficiente para resolver problemas n√£o linearmente separ√°veis como o XOR.
